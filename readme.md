# DNA-PPG: A Foundation Model for Photoplethysmography via Dual Neighborhood Alignment

> **Note:** This repository contains the official PyTorch implementation of the paper **"DNA-PPG: A Foundation Model for Photoplethysmography via Dual Neighborhood Alignment"** submitted to **IJCAI 2026**.

## üöÄ Introduction

**DNA-PPG** is a novel pre-training framework designed to learn robust and universal representations for Photoplethysmography (PPG) signals. It addresses the limitations of existing physiological foundation models‚Äîspecifically the manifold distortion caused by rigid hard-negative sampling and the precision loss from coarse discretization.

Our framework introduces **Dual Neighborhood Alignment**:
1.  **Morphology-Aware Self-Supervised Branch (Morph-SSL):** Uses Time-Frequency Soft Weighting (TF-Soft) to capture universal signal dynamics.
2.  **Physiological Semantic Alignment Branch (Phys-Align):** Projects physiological indicators into a continuous semantic space to embed precise physiological priors.

Pre-trained on **10.7 million PPG segments** from over 8,400 subjects, DNA-PPG achieves state-of-the-art performance on downstream regression and classification tasks.

## üìÇ Repository Structure

```text
.
‚îú‚îÄ‚îÄ baselines/            # Implementations of comparison methods 
‚îú‚îÄ‚îÄ ckpt/                 # Directory for saving model checkpoints
‚îú‚îÄ‚îÄ downstream/           # Code for downstream tasks
‚îú‚îÄ‚îÄ models/               # Model definitions
‚îú‚îÄ‚îÄ preprocessing/        # General preprocessing utilities
‚îú‚îÄ‚îÄ augmentations.py      # Signal augmentations
‚îú‚îÄ‚îÄ dataset.py            # PyTorch Dataset classes for data loading
‚îú‚îÄ‚îÄ dsPreProcess.py       # Preprocessing scripts specific to downstream datasets
‚îú‚îÄ‚îÄ losses.py             # Implementation of Morphology-Aware Loss (L_Morph) and Phys-Align Loss (L_Phys)
‚îú‚îÄ‚îÄ preProcessMesa.py     # Data cleaning and segmentation for MESA dataset
‚îú‚îÄ‚îÄ preProcessVital.py    # Data cleaning and segmentation for VitalDB dataset
‚îú‚îÄ‚îÄ train.py              # Main pre-training script
‚îú‚îÄ‚îÄ utilities.py          # General helper functions
‚îî‚îÄ‚îÄ README.md             # This file
```

## üõ†Ô∏è Environment Requirements

To reproduce the experiments, please set up the environment using the following dependencies:

- Python 3.8+
- PyTorch >= 1.12
- NumPy
- SciPy
- Pandas
- Scikit-learn
- Tqdm

```bash
pip install torch numpy scipy pandas scikit-learn tqdm
```

## üìä Data Preparation

Due to privacy regulations and licensing agreements, we cannot provide the raw datasets directly. Please request access from the official sources:

### Pre-training Datasets

1. **VitalDB:** https://physionet.org/content/vitaldb/
2. **MESA:** https://sleepdata.org/datasets/mesa

After downloading, place the raw data in a local directory and run the specific preprocessing scripts to generate 10-second segments and align physiological labels:

```bash
# Preprocess VitalDB
python preProcessVital.py

# Preprocess MESA
python preProcessMesa.py
```

### Downstream Datasets

Refer to `dsPreProcess.py` for handling downstream datasets (PPG-BP, PPG-DaLiA, WESAD, etc.).

## üöÄ Usage

### 1. Pre-training

To pre-train the DNA-PPG model using the Dual Neighborhood Alignment strategy (jointly optimizing $L_M$ and $L_P$):

```bash
python train.py --epoch 10 --model "resnet1d" --transform_ssl --transform_sup --use-tfc --data-source "all"
```

### 2. Downstream Evaluation

To fine-tune the pre-trained encoder on specific tasks:

```bash
python dsPreProcess.py
python -m downstream.parallel_executor
cd downstream/
python outcome_regression_all.py --model model_path
python outcome_classification_all.py --model model_path
```

## üìù Citation

If you find this code useful, please cite our paper (BibTeX will be updated after the review process):

```bibtex
@article{DNA-PPG2026,
  title={DNA-PPG: A Foundation Model for Photoplethysmography via Dual Neighborhood Alignment},
  author={Anonymous Authors},
  journal={Submitted to IJCAI},
  year={2026}
}
```

## üôè Acknowledgements

We thank the authors of the following open-source projects, whose codebases provided valuable foundations for this work:

- **PaPaGei:** https://github.com/Nokia-Bell-Labs/papagei-foundation-model
- **TF-C:** https://github.com/mims-harvard/TFC-pretraining

## ‚öñÔ∏è License

This project is licensed under the MIT License. See the LICENSE file for details.